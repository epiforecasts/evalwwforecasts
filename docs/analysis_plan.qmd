# Analysis plan

This document describes the analysis plan to perform a retrospective evaluation of the impact of incorporating wastewater data on the forecast performance of a semi-mechanistic renewal-based model, specifically the model available in the [@wwinference] R package.
Forecasts of COVID-19 hospital admissions will be generated weekly and evaluated against the final observed hospital admissions data, across all age groups in Germany during the 2024-2025 respiratory virus season. 

# Aims

The goal of these analyses will be to assess:
1. How does incorporating wastewater impact the forecast performance of a semi-mechanistic renewal model? 
3. How do characteristics of the wastewater surveillance system impact the relative forecast performance of the wastewater-informed model?


# Data

This analysis will use publicly available data from RKI of COVID-19 hospital admissions at the state-level and wastewater concentration data at the site-level in Germany during the 2024-2025 respiratory virus season.
We will use GitHub's commit history of both repositories to generate snapshots of each data source available as of each forecast date.
Weekly snapshots of both datasets will be created every Monday from October 2024 to March 2025.

## Hospital admissions data

Hospital admissions data are reported by age group and state as 7-day rolling sums.
We will fit and generate forecasts for all age groups, at the state-level.
We will take the difference between successive days to compute daily hospital admissions incidence as an input into the model. 

### Addressing right-truncation
The hospital admissions data provided are indexed by the data of the positive test -- which is sometimes well before patients end up hospitalised, leading to a right-truncation problem described in [@Wolffram2023].

We will address this by separately estimating a delay distribution for each region and forecast date using `baselinenowcast`, and modifying the `wwinference` model to account for right-truncated data via incorporating a reporting delay in the observation model.

## Wastewater concentration data
Data on wastewater concentrations of SARS-CoV-2 are available from individual wastewater treatment plants (will refer to these as sites), indexed by sample collection date.
Each wastewater treatment plant is contained within a state, and contains the metadata on the catchment area (population size) served by the wastewater treatment plant.
We will assume all individuals served by the wastewater treatment plant reside within the state.
We will jointly fit to all wastewater treatment plants within a state.

# Models
- `wwinference` (ww + hosp): This model will jointly fit to the daily hospital admissions at the state-level and the wastewater concentration data from the treatment plants within the state.
- `wwinference` (normalized ww + hosp): This model will jointly fit to the daily hospital admissions at the state level and the flow-population normalized data from the individual treatment 
 plants within the state.
- `wwinference` (state ww + hosp): This model will jointly fit to the daily hospital admissions and average wastewater concentration, both at the state-level. 
- `wwinference` (hosp only): This model will be fit only to the daily hospital admissions at the state-level



In the SI, we will compare performance of both these models to a baseline auto-ARIMA model fit only to the right-truncation corrected hospital admissions data.  

# Forecasts
Forecasts will be generated from each of the 4 models for all location-forecast dates where wastewater data is available.
Forecasts will be generated at a daily temporal resolution, each week, for  a 28 day horizon ahead of the forecast date, from October 2024 to March 2025.

## Evaluation
Visual comparisons of forecasts overlaid with evaluation data will be used to assess the forecast performance of each model.

The forecast performance will be evaluated against the final hospital admissions dataset available in June of 2025.
Posterior samples of forecasts will be log-transformed, along with the observations the models are evaluated against.
Forecasts will be scored using proper scoring rules, with metrics including the CRPS, coverage, and bias.

We will typically summarise and analyse scores at the level of each individual forecast problem (a specific forecast date-location combination).
This means we will summarise across the 28 horizon days to get an absolute score for each forecas problem, unless we specifically state we are investigating performance stratified by horizon. 


We will then present the results by analysing the distributions of absolute scores for each forecast in the following analyses (to be made into figures):
- CRPS by model summarised across locations and forecast dates, broken down by under/over prediction and dispersion, in the form of a horizontal bar chart for each of the models, for 3 different horizons (7, 14, 28 day horizon).
- CRPS by model summarised across forecast dates, stratified by location (heatmap x-axis = model, y-axis = location)
- CRPS by model summarised across locations, stratified by forecast date (line plot x-axis = date, y-axis = CRPS, color = model)
- 50th and 90th interval coverage summarised across locations and forecast dates (horizontal bar chart, color = model)
- distribution of relative CRPS scores compared to wwinference (hosp only) (histograms, colored by model)


### Model-based evaluation: model comparison

The above figures describe an attempt to understand trends in the performance of the two individual models by stratifying by forecast date, location, and horizon. 
To extend this analysis, we will also perform a model-based evaluation in an attempt to account for the impact of different confounding variables on forecast performance, similar to the approach described in [@Sherratt2025].

We will account for the following confounding variables that we expect to have an impact on forecast performance:
- location
- forecast date and location 
- horizon
- epidemic phase
- model

Resulting in the following model formulation:

$$
CRPS_{h,d,l,m} \sim \beta + s(location, bs = "re") + s(forecastdate, by = location) + s(horizon, k ) + s(epidemicphase, bs = "re") + s(model, bs = "re")
$$
Where $h$ is the forecast horizon (from 1 to 28 days), $d$ is the forecast date, $l$ is the location of the forecast (in this case which state), and $m$ is the model (either `ww+hosp` or `hosp_only`). 
The goal of this analysis will be to estimate the effect of the model via the $s(model, bs = "re")$ term while taking into account the many additional confounding variables that contribute to forecast performance. 

## Model-based evaluation: understanding role of wastewater surveillance system
We will then perform an exploratory analysis into the influence of the wastewater surveillance system on the relative performance of the "ww + hosp" model compared to the "hosp only" model. 

We will include the following variables with which we would like to understand their impact on relative forecast performance:
- score of the `hosp_only` model
- number of wastewater treatment plants(sites)
- population coverage of all the wastewater treatment plants
- average sampling frequency across sites
- average latency from last collection date to the forecast date

Resulting in the following model formulation: 
$$
CRPS^{ww+hosp}_{h,d,l} \sim \beta + CRPS^{hosponly}_{h,d,l}+ s(numberofsites, k ) + s(popcoverageww, k ) + s(avgfreqsampling, k) + s(avglatencyreporting,k)
$$
The idea behind this analysis will be that the CRPS score for the `hosp_only` model accounts for the baseline "difficulty"in that particular location $l$, at forecast date $d$ and horizon $h$. 
Each of the additional components has some (assumed to be non-linear) positive or negative impact on the relative forecast performance of the wastewater-informed model that we would like to estimate. 

We will plot the partial effects as a function of the number of sites, population coverage of wastewater surveillance, the average sampling frequency in the wastewater data and the average latency in reporting of the wastewater data. 

The estimated $\beta$ reflects the adjusted additive impact of incorporating wastewater on forecast performance taking into account the other confounding variables. 
We will implement this using a linear-link function in the R package `mgcv`.
These exploratory analyses will be used to generate hypotheses into the impact of the characteristics of wastewater surveillance system on the performance of the `wwinference` model. 

## Additional extension

We might consider incorporating an additional wastewater-informed model of an entirely different model type, e.g. a ML based approach. 
This would expand the current scope a bit but would not change the planned analyses significantly as we would just add an additional model to all of the planned evaluation analyses (and consider doing a separate regression approach for a ML based approach with and without wastewater). 



